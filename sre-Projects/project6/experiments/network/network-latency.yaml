##############################################################################
# Experiment: Network Latency Injection
#
# Hypothesis: The application handles increased network latency between
#             services without timing out or cascading failures.
# Validates: Timeout configurations, async patterns, user experience.
#
# Expected Behavior:
# - Requests between services become slower (added latency)
# - Services with proper timeouts handle it gracefully
# - Users see slower responses but not errors
# - Latency SLO alerts may fire (expected)
##############################################################################
---
apiVersion: litmuschaos.io/v1alpha1
kind: ChaosEngine
metadata:
  name: network-latency-chaos
  namespace: sre-demo
  labels:
    experiment: network-latency
    severity: medium
spec:
  engineState: active
  appinfo:
    appns: sre-demo
    applabel: app=frontend
    appkind: deployment
  chaosServiceAccount: chaos-admin
  experiments:
    - name: pod-network-latency
      spec:
        components:
          env:
            - name: TOTAL_CHAOS_DURATION
              value: "120"
            # Latency to inject (milliseconds)
            - name: NETWORK_LATENCY
              value: "500"
            # Jitter (randomness in latency)
            - name: JITTER
              value: "100"
            - name: PODS_AFFECTED_PERC
              value: "100"
            - name: CONTAINER_RUNTIME
              value: containerd
            - name: SOCKET_PATH
              value: /run/containerd/containerd.sock
        probe:
          - name: latency-threshold
            type: promProbe
            mode: Continuous
            promProbe/inputs:
              endpoint: http://prometheus-operated.monitoring.svc.cluster.local:9090
              query: histogram_quantile(0.99, sum(rate(http_request_duration_seconds_bucket{namespace="sre-demo"}[1m])) by (le))
              comparator:
                type: float
                criteria: "<="
                value: "5.0"
            runProperties:
              probeTimeout: 10s
              interval: 15s
              retry: 3
---
# Manual execution alternative
apiVersion: batch/v1
kind: Job
metadata:
  name: network-latency-manual
  namespace: sre-demo
  labels:
    experiment: network-latency
    type: manual
spec:
  template:
    spec:
      serviceAccountName: chaos-admin
      restartPolicy: Never
      containers:
        - name: chaos-runner
          image: bitnami/kubectl:latest
          command:
            - /bin/bash
            - -c
            - |
              echo "=== Network Latency Experiment ==="
              echo "Simulating slow dependency responses"
              echo "Duration: 120s"
              echo ""

              # Measure baseline latency
              POD=$(kubectl get pods -n sre-demo -l app=frontend \
                -o jsonpath='{.items[0].metadata.name}')

              echo "[BEFORE] Baseline latency test..."
              for i in 1 2 3; do
                START=$(date +%s%N)
                kubectl exec -n sre-demo "$POD" -- wget -q -O /dev/null --timeout=10 \
                  http://productcatalogservice:3550/ 2>/dev/null
                END=$(date +%s%N)
                LATENCY=$(( (END - START) / 1000000 ))
                echo "  Request $i: ${LATENCY}ms"
              done

              echo ""
              echo "[ACTION] Injecting latency by reducing resource limits..."
              # Simulate latency by constraining CPU (causes processing delays)
              kubectl patch deployment frontend -n sre-demo --type=json \
                -p='[{"op":"replace","path":"/spec/template/spec/containers/0/resources/limits/cpu","value":"50m"}]' 2>/dev/null || true

              echo "[INFO] Monitoring for 120s..."
              for i in $(seq 1 12); do
                sleep 10
                echo "  [$(date -u '+%H:%M:%S')] Frontend pods:"
                kubectl get pods -n sre-demo -l app=frontend --no-headers | \
                  awk '{printf "    %s â€” %s (restarts: %s)\n", $1, $3, $4}'
              done

              echo ""
              echo "[ACTION] Restoring original CPU limits..."
              kubectl patch deployment frontend -n sre-demo --type=json \
                -p='[{"op":"replace","path":"/spec/template/spec/containers/0/resources/limits/cpu","value":"200m"}]' 2>/dev/null || true

              echo "[INFO] Waiting 30s for recovery..."
              sleep 30

              echo ""
              echo "[AFTER] Recovery latency test..."
              POD=$(kubectl get pods -n sre-demo -l app=frontend \
                --field-selector=status.phase=Running \
                -o jsonpath='{.items[0].metadata.name}')
              for i in 1 2 3; do
                START=$(date +%s%N)
                kubectl exec -n sre-demo "$POD" -- wget -q -O /dev/null --timeout=10 \
                  http://productcatalogservice:3550/ 2>/dev/null
                END=$(date +%s%N)
                LATENCY=$(( (END - START) / 1000000 ))
                echo "  Request $i: ${LATENCY}ms"
              done
              echo ""
              echo "=== Experiment Complete ==="
  backoffLimit: 0
