# Karpenter NodePool for spot instances
# Used for fault-tolerant workloads: batch jobs, dev, CI/CD
apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: spot-workloads
spec:
  template:
    metadata:
      labels:
        node.kubernetes.io/lifecycle: spot
        nodepool: spot-workloads
    spec:
      # Use spot instances only
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["spot"]
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: kubernetes.io/os
          operator: In
          values: ["linux"]
        # Diversify across multiple instance types to reduce interruption risk
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - m5.large
            - m5.xlarge
            - m5a.large
            - m5a.xlarge
            - m6i.large
            - m6i.xlarge
            - m6a.large
            - m6a.xlarge
            - c5.large
            - c5.xlarge
            - c5a.large
            - c5a.xlarge
            - r5.large
            - r5a.large
        - key: topology.kubernetes.io/zone
          operator: In
          values:
            - us-east-1a
            - us-east-1b
            - us-east-1c
      # Taint spot nodes so only tolerant workloads schedule here
      taints:
        - key: kubernetes.io/spot
          value: "true"
          effect: NoSchedule
      nodeClassRef:
        name: spot-node-class
  # Consolidation policy (remove underutilized spot nodes)
  disruption:
    consolidationPolicy: WhenUnderutilized
    consolidateAfter: 30s
    expireAfter: 720h
  # Resource limits for the node pool
  limits:
    cpu: "200"
    memory: 400Gi
  # Weight for scheduling preference (lower = preferred)
  weight: 50
---
# On-demand NodePool for production workloads
apiVersion: karpenter.sh/v1beta1
kind: NodePool
metadata:
  name: on-demand-production
spec:
  template:
    metadata:
      labels:
        node.kubernetes.io/lifecycle: on-demand
        nodepool: on-demand-production
    spec:
      requirements:
        - key: karpenter.sh/capacity-type
          operator: In
          values: ["on-demand"]
        - key: kubernetes.io/arch
          operator: In
          values: ["amd64"]
        - key: node.kubernetes.io/instance-type
          operator: In
          values:
            - m6i.large
            - m6i.xlarge
            - m6i.2xlarge
        - key: topology.kubernetes.io/zone
          operator: In
          values:
            - us-east-1a
            - us-east-1b
            - us-east-1c
      nodeClassRef:
        name: on-demand-node-class
  disruption:
    consolidationPolicy: WhenUnderutilized
    consolidateAfter: 60s
    expireAfter: 2160h
  limits:
    cpu: "500"
    memory: 1000Gi
  weight: 10
---
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: spot-node-class
spec:
  amiFamily: AL2
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: production-cluster
        kubernetes.io/role/internal-elb: "1"
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: production-cluster
  instanceProfile: KarpenterNodeInstanceProfile
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 50Gi
        volumeType: gp3
        iops: 3000
        throughput: 125
        encrypted: true
        deleteOnTermination: true
  tags:
    Environment: production
    ManagedBy: karpenter
    CostCenter: platform
    Lifecycle: spot
  userData: |
    #!/bin/bash
    # Install AWS Node Termination Handler for graceful spot interruption
    echo "Spot instance provisioned by Karpenter"
---
apiVersion: karpenter.k8s.aws/v1beta1
kind: EC2NodeClass
metadata:
  name: on-demand-node-class
spec:
  amiFamily: AL2
  subnetSelectorTerms:
    - tags:
        karpenter.sh/discovery: production-cluster
        kubernetes.io/role/internal-elb: "1"
  securityGroupSelectorTerms:
    - tags:
        karpenter.sh/discovery: production-cluster
  instanceProfile: KarpenterNodeInstanceProfile
  blockDeviceMappings:
    - deviceName: /dev/xvda
      ebs:
        volumeSize: 100Gi
        volumeType: gp3
        iops: 3000
        throughput: 125
        encrypted: true
        deleteOnTermination: true
  tags:
    Environment: production
    ManagedBy: karpenter
    CostCenter: platform
    Lifecycle: on-demand
---
# Example batch workload that tolerates spot instances
apiVersion: batch/v1
kind: Job
metadata:
  name: batch-data-processing
  namespace: batch-jobs
  labels:
    workload-type: batch
    cost-center: data-platform
spec:
  parallelism: 5
  completions: 20
  backoffLimit: 10
  template:
    metadata:
      labels:
        workload-type: batch
    spec:
      # Schedule on spot instances
      tolerations:
        - key: kubernetes.io/spot
          operator: Equal
          value: "true"
          effect: NoSchedule
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - weight: 90
              preference:
                matchExpressions:
                  - key: node.kubernetes.io/lifecycle
                    operator: In
                    values:
                      - spot
      # Terminate gracefully on spot interruption
      terminationGracePeriodSeconds: 120
      containers:
        - name: processor
          image: registry.example.com/batch-processor:v2.1.0
          command: ["python", "process.py"]
          resources:
            requests:
              cpu: 500m
              memory: 1Gi
            limits:
              cpu: "2"
              memory: 4Gi
      restartPolicy: OnFailure
